# from Probabilistic Robotics p.450

particle = individiual state estimate + 1 kalman filter per map feature (total of N)
Particle filter: M particles

const M = 50
N = 0 to start, adding more as I go algon

# --- v1 (direct from book, bearing + range - color) ---
#  algorithm assumes known correspondences for now
#  color will make this known correspondences originally

for each particle:
	have the particle from the previous time step (t-1)

	# generate a new state based on the control
	state at t = noisy_motion_model(state at t-1, control at t)

	# for an observed feature j
	if feature j never seen before:
		feature estimate mean = inverse_measurement_model(state at t, measurement)

		# ekf style update for covariance
		H = derivative of motion model (Jacobian, linearization based on state at t, feature estimate mean)
		Qt = process noise

		feature estimate covariance = H-inverse * Qt * (H-inverse)-transpose

		weight = default importance p0

		add it back to the list of features for the particle

	else feature seen before:
		z hat = measurement prediction based on measurement model
		H = derivative of motion model (Jacobian, linearization)
		Qt = process noise

		Q = H * (old feature estimate covariance) * H-transpose + Qt

		K = kalman gain = (old feature estimate covariance) * H-transpose * Q-inverse

		new feature estimate mean = old feature estimate mean + K( measurement - z hat)

		new feature estimate covariance = (Identity matrix - K * H)*(old feature estimate covariance)

		weight = some calculation as a function of (Q, measurement - z hat)

	for all other features not seen by the current measurement:
		don't update!

# done looping over old particles

# resample existing particle list

Create a new temp particle list

for i = 0, i < length of old particles list, i++:
	draw index k with a probability proportional to the weight of particle k
	add particle k to the new particle list

return new particle list


# --- v1.1 a more "python"-y version ---
#  algorithm assumes known correspondences for now
#  color will make this known correspondences originally

import math.pi as pi

particle = individiual state estimate + 1 kalman filter per map feature (total of N)
Particle filter: M particles

particle_list = [new_particle() * 1000]

const M = 50
N = 0 to start, adding more as I go algon
const Qt = process noise

between calls to the function:
control = current_robot_control()
zt = observation = next_measurement()
j = zt.feature_id

# loop over existing particles to update with new data

for particle in old_particles:
	
	# generate a new state based on the control
	particle.new_state = noisy_motion_model(particle.old_state, control)
	
	# for an observed feature j
	if not j.seen_before():
		new_mean = inverse_measurement_model(particle.new_state, zt)

		# ekf style update for covariance
		H = jacobian_linearization_of_motion_model(particle.new_state, new_mean)
		
		new_covar = inverse(H) * Qt * transpose(inverse(H))

		particle.add_new_feature_ekf(new_mean, new_covar)

		particle.weight = default_weight()

	else: # feature seen before
		k = get_matching_feature_index(j)
		old_measurement_ekf = get_feature_by_index(k)
		z_hat = measurement_prediction(old_measurement_ekf.mean, particle.new_state)
		H = jacobian_linearization_of_motion_model(particle.new_state, old_measurement_ekf.mean)
		
		Q = H * old_measurement_ekf.covar * transpose(H) + Qt

		K = old_measurement_ekf.covar * transpose(H) * inverse(Q)

		new_mean = old_measurement_ekf.mean + K( zt - z_hat)

		new_covar = (identity_matrix() - K * H)*(old_measurement_ekf.covar)

		particle.replace_feature_ekf(k, new_mean, new_covar)

		particle.weight = pow(2*pi*magnitude(Q), -1/2) * exp(-1/2 * transpose(zt - z_hat) * inverse(Q) * (zt - z_hat))

# done looping over old particles

# resample existing particle list

new_particle_list = []

sum = 0
for particle in particle_list:
	sum = sum + particle.weight

chosen = rand_in_range(0, sum)

for _ = range(0, len(particle_list)):
	for particle in particle_list:
		chosen = chosen - particle.weight
		if chosen < 0:
			# choose this particle
			new_particle_list.append(deep_copy(particle))

particle_list = new_particle_list

# --- v1.1 a more ROS "python"-y version ---
#  measurements come in as callbacks
#  algorithm assumes known correspondences for now
#  color will make this known correspondences originally

import rospy
import math.pi as pi

def startup(...)

	# particle = individiual state estimate + 1 kalman filter per map feature (total of N)
	# Particle filter: M particles
	const M = 50 # = number of particles

	particle_list = [new_particle() * M]

	const Qt = process noise

	last_motion_update_time = rospy.time.now()
	last_control = Twist() # initialize to all 0s

def command_update_callback(new_control):
	# do a motion update only to the current time (time of new command)
	motion_update(new_control)

def motion_update(new_control):
	new_time = rospy.time.now()
	dt = new_time - last_motion_update_time
	for particle in particle_list:
		particle.state = noisy_motion_model(particle.state, last_control, dt)
	last_motion_update_time = new_time
	last_control = new_control


def measurement_update_callback(new_measurement):
	# do a motion update (sampling), then do a measurement update (thru resampling)
	motion_update(last_control) # this won't change the last_control

	zt = new_measurement
	
	for particle in particle_list:
		j = particle.get_feature_id(zt) # it will be particle dependent
		if not j.seen_before(): # measured feature doesn't match existing particle-ekf
			new_mean = inverse_measurement_model(particle.state, zt)

			# ekf style update for covariance
			H = jacobian_linearization_of_motion_model(particle.state, new_mean)
			
			new_covar = inverse(H) * Qt * transpose(inverse(H))

			particle.add_new_feature_ekf(new_mean, new_covar)

			particle.weight = particle.default_weight()

		else: # measured feature matches existing particle-ekf
			old_measurement_ekf = particle.get_feature_by_id(j)
			z_hat = measurement_prediction(old_measurement_ekf.mean, particle.state)
			H = jacobian_linearization_of_motion_model(particle.state, old_measurement_ekf.mean)
			
			Q = H * old_measurement_ekf.covar * transpose(H) + Qt

			K = old_measurement_ekf.covar * transpose(H) * inverse(Q)

			new_mean = old_measurement_ekf.mean + K( zt - z_hat)

			new_covar = (identity_matrix() - K * H)*(old_measurement_ekf.covar)

			particle.replace_feature_ekf(j, new_mean, new_covar)

			particle.weight = pow(2*pi*magnitude(Q), -1/2) * exp(-1/2 * transpose(zt - z_hat) * inverse(Q) * (zt - z_hat))

	# done looping over old particles

	# resample existing particle list

	new_particle_list = []

	sum = 0
	for particle in particle_list:
		sum = sum + particle.weight

	chosen = rand_in_range(0, sum)

	for _ = range(0, len(particle_list)):
		for particle in particle_list:
			chosen = chosen - particle.weight
			if chosen < 0:
				# choose this particle
				new_particle_list.append(deep_copy(particle))

	particle_list = new_particle_list